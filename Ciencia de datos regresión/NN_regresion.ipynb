{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25970d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"BarcelonaAbnb_limpio.csv\")\n",
    "df\n",
    "import numpy as np\n",
    "\n",
    "df[\"log_price\"] = np.log1p(df[\"price\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b36b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([210., 285., 170., ...,  90.,  90., 120.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reg = df[\"price\"].values\n",
    "y_reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7992b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_response_time</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>...</th>\n",
       "      <th>room_type_Shared room</th>\n",
       "      <th>neighbourhood_group_cleansed_Eixample</th>\n",
       "      <th>neighbourhood_group_cleansed_Gràcia</th>\n",
       "      <th>neighbourhood_group_cleansed_Horta-Guinardó</th>\n",
       "      <th>neighbourhood_group_cleansed_Les Corts</th>\n",
       "      <th>neighbourhood_group_cleansed_Nou Barris</th>\n",
       "      <th>neighbourhood_group_cleansed_Sant Andreu</th>\n",
       "      <th>neighbourhood_group_cleansed_Sant Martí</th>\n",
       "      <th>neighbourhood_group_cleansed_Sants-Montjuïc</th>\n",
       "      <th>neighbourhood_group_cleansed_Sarrià-Sant Gervasi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.405560</td>\n",
       "      <td>2.172620</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.412432</td>\n",
       "      <td>2.219750</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.405660</td>\n",
       "      <td>2.170150</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.380620</td>\n",
       "      <td>2.175170</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.379780</td>\n",
       "      <td>2.176230</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13410</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.382010</td>\n",
       "      <td>2.177120</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13411</th>\n",
       "      <td>1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.410689</td>\n",
       "      <td>2.170413</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13412</th>\n",
       "      <td>1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.390695</td>\n",
       "      <td>2.164782</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13413</th>\n",
       "      <td>1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.396987</td>\n",
       "      <td>2.166294</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13414</th>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.380181</td>\n",
       "      <td>2.154822</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13415 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       host_response_time  host_response_rate  host_acceptance_rate  \\\n",
       "0                     0.0                96.0                  91.0   \n",
       "1                     0.0               100.0                  96.0   \n",
       "2                     0.0               100.0                 100.0   \n",
       "3                     0.0               100.0                  92.0   \n",
       "4                     0.0               100.0                  92.0   \n",
       "...                   ...                 ...                   ...   \n",
       "13410                 1.0               100.0                  98.0   \n",
       "13411                 1.0                87.0                   6.0   \n",
       "13412                 1.0                87.0                   6.0   \n",
       "13413                 1.0                87.0                   6.0   \n",
       "13414                 0.0                98.0                  98.0   \n",
       "\n",
       "       host_is_superhost  host_has_profile_pic  host_identity_verified  \\\n",
       "0                    0.0                   1.0                     1.0   \n",
       "1                    1.0                   1.0                     1.0   \n",
       "2                    0.0                   1.0                     1.0   \n",
       "3                    0.0                   1.0                     1.0   \n",
       "4                    0.0                   1.0                     1.0   \n",
       "...                  ...                   ...                     ...   \n",
       "13410                0.0                   1.0                     1.0   \n",
       "13411                0.0                   1.0                     1.0   \n",
       "13412                0.0                   1.0                     1.0   \n",
       "13413                0.0                   1.0                     1.0   \n",
       "13414                0.0                   1.0                     1.0   \n",
       "\n",
       "        latitude  longitude  accommodates  bathrooms  ...  \\\n",
       "0      41.405560   2.172620           8.0        2.0  ...   \n",
       "1      41.412432   2.219750           5.0        2.0  ...   \n",
       "2      41.405660   2.170150           6.0        2.0  ...   \n",
       "3      41.380620   2.175170           2.0        1.0  ...   \n",
       "4      41.379780   2.176230           9.0        3.0  ...   \n",
       "...          ...        ...           ...        ...  ...   \n",
       "13410  41.382010   2.177120           5.0        1.0  ...   \n",
       "13411  41.410689   2.170413           3.0        1.0  ...   \n",
       "13412  41.390695   2.164782           4.0        1.0  ...   \n",
       "13413  41.396987   2.166294           4.0        1.0  ...   \n",
       "13414  41.380181   2.154822           4.0        1.0  ...   \n",
       "\n",
       "       room_type_Shared room  neighbourhood_group_cleansed_Eixample  \\\n",
       "0                          0                                      1   \n",
       "1                          0                                      0   \n",
       "2                          0                                      0   \n",
       "3                          0                                      0   \n",
       "4                          0                                      0   \n",
       "...                      ...                                    ...   \n",
       "13410                      0                                      0   \n",
       "13411                      0                                      0   \n",
       "13412                      0                                      1   \n",
       "13413                      0                                      1   \n",
       "13414                      0                                      1   \n",
       "\n",
       "       neighbourhood_group_cleansed_Gràcia  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        1   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "...                                    ...   \n",
       "13410                                    0   \n",
       "13411                                    0   \n",
       "13412                                    0   \n",
       "13413                                    0   \n",
       "13414                                    0   \n",
       "\n",
       "       neighbourhood_group_cleansed_Horta-Guinardó  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "...                                            ...   \n",
       "13410                                            0   \n",
       "13411                                            1   \n",
       "13412                                            0   \n",
       "13413                                            0   \n",
       "13414                                            0   \n",
       "\n",
       "       neighbourhood_group_cleansed_Les Corts  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "...                                       ...   \n",
       "13410                                       0   \n",
       "13411                                       0   \n",
       "13412                                       0   \n",
       "13413                                       0   \n",
       "13414                                       0   \n",
       "\n",
       "       neighbourhood_group_cleansed_Nou Barris  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "...                                        ...   \n",
       "13410                                        0   \n",
       "13411                                        0   \n",
       "13412                                        0   \n",
       "13413                                        0   \n",
       "13414                                        0   \n",
       "\n",
       "       neighbourhood_group_cleansed_Sant Andreu  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "...                                         ...   \n",
       "13410                                         0   \n",
       "13411                                         0   \n",
       "13412                                         0   \n",
       "13413                                         0   \n",
       "13414                                         0   \n",
       "\n",
       "       neighbourhood_group_cleansed_Sant Martí  \\\n",
       "0                                            0   \n",
       "1                                            1   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "...                                        ...   \n",
       "13410                                        0   \n",
       "13411                                        0   \n",
       "13412                                        0   \n",
       "13413                                        0   \n",
       "13414                                        0   \n",
       "\n",
       "       neighbourhood_group_cleansed_Sants-Montjuïc  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "...                                            ...   \n",
       "13410                                            0   \n",
       "13411                                            0   \n",
       "13412                                            0   \n",
       "13413                                            0   \n",
       "13414                                            0   \n",
       "\n",
       "       neighbourhood_group_cleansed_Sarrià-Sant Gervasi  \n",
       "0                                                     0  \n",
       "1                                                     0  \n",
       "2                                                     0  \n",
       "3                                                     0  \n",
       "4                                                     0  \n",
       "...                                                 ...  \n",
       "13410                                                 0  \n",
       "13411                                                 0  \n",
       "13412                                                 0  \n",
       "13413                                                 0  \n",
       "13414                                                 0  \n",
       "\n",
       "[13415 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_excluir_reg = [\n",
    "    \"price\",\n",
    "    \"estimated_revenue_l365d\"\n",
    "    ,  \"log_price\"\n",
    "]\n",
    "\n",
    "X_reg = df.drop(columns=cols_excluir_reg)\n",
    "X_reg = X_reg.select_dtypes(include=[\"number\"])\n",
    "\n",
    "X_reg \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dde8db51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e9feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_reg = StandardScaler()\n",
    "X_train_reg_scaled = scaler_reg.fit_transform(X_train_reg)\n",
    "X_test_reg_scaled = scaler_reg.transform(X_test_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c68f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_regression_model(\n",
    "    n_features,\n",
    "    n_hidden1=128,\n",
    "    n_hidden2=64,\n",
    "    n_hidden3=32,\n",
    "    dropout_rate=0.2,\n",
    "    learning_rate=1e-3\n",
    "):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(n_features,)),\n",
    "        layers.Dense(n_hidden1, activation=\"relu\"),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(n_hidden2, activation=\"relu\"),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(n_hidden3, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"linear\") \n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d766ac85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8305.8389 - mae: 62.9349 - val_loss: 3275.1367 - val_mae: 41.4160\n",
      "Epoch 2/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3336.2422 - mae: 41.4538 - val_loss: 3038.8176 - val_mae: 40.1804\n",
      "Epoch 3/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3135.7705 - mae: 39.9749 - val_loss: 2925.2815 - val_mae: 38.6039\n",
      "Epoch 4/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3100.3394 - mae: 39.5384 - val_loss: 2856.0815 - val_mae: 38.5295\n",
      "Epoch 5/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3024.9380 - mae: 39.1410 - val_loss: 2820.3457 - val_mae: 38.5723\n",
      "Epoch 6/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2942.8643 - mae: 38.7092 - val_loss: 2773.7166 - val_mae: 37.9574\n",
      "Epoch 7/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2899.2544 - mae: 38.3581 - val_loss: 2784.0046 - val_mae: 38.0939\n",
      "Epoch 8/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2896.7419 - mae: 38.2727 - val_loss: 2792.4207 - val_mae: 38.2457\n",
      "Epoch 9/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2887.5305 - mae: 38.1734 - val_loss: 2789.9060 - val_mae: 38.1084\n",
      "Epoch 10/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2828.4458 - mae: 37.8382 - val_loss: 2717.3042 - val_mae: 37.3236\n",
      "Epoch 11/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2824.8037 - mae: 37.8504 - val_loss: 2694.4492 - val_mae: 37.7854\n",
      "Epoch 12/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2768.2185 - mae: 37.3098 - val_loss: 2734.9546 - val_mae: 37.3793\n",
      "Epoch 13/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2781.3650 - mae: 37.5227 - val_loss: 2644.9712 - val_mae: 36.9048\n",
      "Epoch 14/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2737.6555 - mae: 37.2529 - val_loss: 2669.9866 - val_mae: 37.1324\n",
      "Epoch 15/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2680.2043 - mae: 36.8050 - val_loss: 2720.0935 - val_mae: 36.6965\n",
      "Epoch 16/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2683.4272 - mae: 36.7600 - val_loss: 2617.7083 - val_mae: 36.7714\n",
      "Epoch 17/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2659.0020 - mae: 36.5792 - val_loss: 2584.4314 - val_mae: 36.3882\n",
      "Epoch 18/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2613.3735 - mae: 36.3068 - val_loss: 2604.0369 - val_mae: 36.4333\n",
      "Epoch 19/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2604.1611 - mae: 36.1667 - val_loss: 2602.2034 - val_mae: 35.9820\n",
      "Epoch 20/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2568.1714 - mae: 36.0865 - val_loss: 2547.9241 - val_mae: 36.2450\n",
      "Epoch 21/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2549.2134 - mae: 36.0169 - val_loss: 2570.2476 - val_mae: 36.3914\n",
      "Epoch 22/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2541.0234 - mae: 35.7063 - val_loss: 2542.4280 - val_mae: 35.9054\n",
      "Epoch 23/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2515.8413 - mae: 35.5988 - val_loss: 2517.5391 - val_mae: 35.4047\n",
      "Epoch 24/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2479.8477 - mae: 35.2487 - val_loss: 2492.7830 - val_mae: 35.3089\n",
      "Epoch 25/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2486.2354 - mae: 35.4987 - val_loss: 2488.2202 - val_mae: 35.3825\n",
      "Epoch 26/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2470.0046 - mae: 35.2348 - val_loss: 2483.3638 - val_mae: 35.5864\n",
      "Epoch 27/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2479.4080 - mae: 35.3043 - val_loss: 2473.4634 - val_mae: 35.0281\n",
      "Epoch 28/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2450.4092 - mae: 35.1077 - val_loss: 2515.3606 - val_mae: 35.3520\n",
      "Epoch 29/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2477.0540 - mae: 35.3924 - val_loss: 2500.2856 - val_mae: 35.0839\n",
      "Epoch 30/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2436.5938 - mae: 35.0359 - val_loss: 2447.5249 - val_mae: 35.2038\n",
      "Epoch 31/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2373.3523 - mae: 34.6175 - val_loss: 2455.0159 - val_mae: 34.9596\n",
      "Epoch 32/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2356.5847 - mae: 34.3750 - val_loss: 2450.0872 - val_mae: 35.0288\n",
      "Epoch 33/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2344.9851 - mae: 34.3719 - val_loss: 2407.1626 - val_mae: 34.9627\n",
      "Epoch 34/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2386.6941 - mae: 34.5733 - val_loss: 2431.3799 - val_mae: 34.9347\n",
      "Epoch 35/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2349.5193 - mae: 34.4354 - val_loss: 2472.8008 - val_mae: 34.7113\n",
      "Epoch 36/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2333.6123 - mae: 34.2780 - val_loss: 2392.9663 - val_mae: 34.6360\n",
      "Epoch 37/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2366.6907 - mae: 34.4621 - val_loss: 2397.9077 - val_mae: 34.5074\n",
      "Epoch 38/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2287.2649 - mae: 34.0001 - val_loss: 2385.1279 - val_mae: 34.6174\n",
      "Epoch 39/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2305.8228 - mae: 34.1069 - val_loss: 2402.0837 - val_mae: 34.8387\n",
      "Epoch 40/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2290.5674 - mae: 33.8639 - val_loss: 2448.6311 - val_mae: 34.8754\n",
      "Epoch 41/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2292.2922 - mae: 33.9983 - val_loss: 2402.1614 - val_mae: 34.3575\n",
      "Epoch 42/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2284.5540 - mae: 33.7175 - val_loss: 2379.4019 - val_mae: 34.3298\n",
      "Epoch 43/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2246.9521 - mae: 33.7626 - val_loss: 2555.7620 - val_mae: 35.1291\n",
      "Epoch 44/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2209.3540 - mae: 33.3471 - val_loss: 2357.9919 - val_mae: 34.3929\n",
      "Epoch 45/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2235.2896 - mae: 33.4468 - val_loss: 2378.4353 - val_mae: 34.4691\n",
      "Epoch 46/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2158.2605 - mae: 33.0778 - val_loss: 2381.6992 - val_mae: 34.6438\n",
      "Epoch 47/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2148.8792 - mae: 33.0679 - val_loss: 2360.9431 - val_mae: 34.4682\n",
      "Epoch 48/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2181.5085 - mae: 33.1623 - val_loss: 2361.9485 - val_mae: 34.2823\n",
      "Epoch 49/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2199.5688 - mae: 33.3119 - val_loss: 2543.3899 - val_mae: 34.9528\n",
      "Epoch 50/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2154.7371 - mae: 32.8778 - val_loss: 2346.9607 - val_mae: 33.9898\n",
      "Epoch 51/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2137.6484 - mae: 32.8645 - val_loss: 2552.2041 - val_mae: 34.8545\n",
      "Epoch 52/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2167.9197 - mae: 33.0129 - val_loss: 2357.1394 - val_mae: 33.8447\n",
      "Epoch 53/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2128.8196 - mae: 32.7965 - val_loss: 2374.8701 - val_mae: 34.1035\n",
      "Epoch 54/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2136.6562 - mae: 32.9663 - val_loss: 2315.6965 - val_mae: 33.5913\n",
      "Epoch 55/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2121.5854 - mae: 32.6311 - val_loss: 2313.6443 - val_mae: 34.3868\n",
      "Epoch 56/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2122.4783 - mae: 32.6862 - val_loss: 2314.3115 - val_mae: 34.1532\n",
      "Epoch 57/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2132.2549 - mae: 32.6731 - val_loss: 2309.6152 - val_mae: 34.0114\n",
      "Epoch 58/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2095.6287 - mae: 32.5152 - val_loss: 2359.4756 - val_mae: 33.8811\n",
      "Epoch 59/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2095.7083 - mae: 32.5164 - val_loss: 2294.6003 - val_mae: 33.7508\n",
      "Epoch 60/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2044.0479 - mae: 32.4167 - val_loss: 2321.5957 - val_mae: 34.3059\n",
      "Epoch 61/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2050.3540 - mae: 32.0239 - val_loss: 2295.0493 - val_mae: 33.8750\n",
      "Epoch 62/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2092.5566 - mae: 32.4570 - val_loss: 2329.3279 - val_mae: 34.2038\n",
      "Epoch 63/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2021.7480 - mae: 32.0852 - val_loss: 2357.6516 - val_mae: 33.8149\n",
      "Epoch 64/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2049.2778 - mae: 32.2687 - val_loss: 2311.1965 - val_mae: 33.7638\n",
      "Epoch 65/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2024.0183 - mae: 32.1801 - val_loss: 2302.4456 - val_mae: 33.7814\n",
      "Epoch 66/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2014.0775 - mae: 32.0629 - val_loss: 2300.8608 - val_mae: 33.4184\n",
      "Epoch 67/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2026.7937 - mae: 32.0334 - val_loss: 2293.8999 - val_mae: 33.5651\n",
      "Epoch 68/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2041.4692 - mae: 32.0787 - val_loss: 2313.3540 - val_mae: 34.0677\n",
      "Epoch 69/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2008.5537 - mae: 31.8934 - val_loss: 2340.8533 - val_mae: 34.2345\n",
      "Epoch 70/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2032.4048 - mae: 31.8898 - val_loss: 2277.6313 - val_mae: 33.4234\n",
      "Epoch 71/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1980.7380 - mae: 31.7565 - val_loss: 2301.9343 - val_mae: 33.5859\n",
      "Epoch 72/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1941.0021 - mae: 31.4794 - val_loss: 2284.3853 - val_mae: 33.5771\n",
      "Epoch 73/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1991.1589 - mae: 31.8139 - val_loss: 2280.2307 - val_mae: 33.4389\n",
      "Epoch 74/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2000.5690 - mae: 31.7595 - val_loss: 2304.2590 - val_mae: 33.7192\n",
      "Epoch 75/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1996.8135 - mae: 31.5747 - val_loss: 2439.1689 - val_mae: 34.1816\n",
      "Epoch 76/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1952.5045 - mae: 31.3466 - val_loss: 2346.3914 - val_mae: 33.6486\n",
      "Epoch 77/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1952.8439 - mae: 31.3744 - val_loss: 2443.9382 - val_mae: 34.1111\n",
      "Epoch 78/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1959.4659 - mae: 31.4637 - val_loss: 2294.6785 - val_mae: 33.7929\n",
      "Epoch 79/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1933.3364 - mae: 31.2451 - val_loss: 2319.1238 - val_mae: 33.4260\n",
      "Epoch 80/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1914.9589 - mae: 31.2499 - val_loss: 2450.7166 - val_mae: 34.1675\n",
      "Epoch 81/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1895.5757 - mae: 31.0289 - val_loss: 2294.0505 - val_mae: 33.4686\n",
      "Epoch 82/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1928.3160 - mae: 31.1431 - val_loss: 2356.6838 - val_mae: 33.3829\n",
      "Epoch 83/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1899.1487 - mae: 30.9695 - val_loss: 2453.8413 - val_mae: 34.1933\n",
      "Epoch 84/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1897.3546 - mae: 30.8992 - val_loss: 2310.5420 - val_mae: 33.3558\n",
      "Epoch 85/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1856.5841 - mae: 30.7506 - val_loss: 2328.3196 - val_mae: 33.4483\n",
      "Epoch 86/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1924.8373 - mae: 31.0327 - val_loss: 2310.4058 - val_mae: 33.3104\n",
      "Epoch 87/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1917.5509 - mae: 31.2520 - val_loss: 2325.4666 - val_mae: 33.5248\n",
      "Epoch 88/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1869.5015 - mae: 30.9917 - val_loss: 2604.0500 - val_mae: 35.0706\n",
      "Epoch 89/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1848.1312 - mae: 30.7027 - val_loss: 2429.0012 - val_mae: 34.0413\n",
      "Epoch 90/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1827.0369 - mae: 30.3026 - val_loss: 2330.7405 - val_mae: 33.2150\n",
      "Epoch 91/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1872.5876 - mae: 30.5950 - val_loss: 2304.7000 - val_mae: 33.1471\n",
      "Epoch 92/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1876.3571 - mae: 30.8050 - val_loss: 2503.5454 - val_mae: 34.2882\n",
      "Epoch 93/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1887.3383 - mae: 30.9209 - val_loss: 2438.3752 - val_mae: 33.9172\n",
      "Epoch 94/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1841.6038 - mae: 30.5492 - val_loss: 2393.4321 - val_mae: 33.7644\n",
      "Epoch 95/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1852.0969 - mae: 30.6314 - val_loss: 2656.9778 - val_mae: 35.2384\n",
      "Epoch 96/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1801.4879 - mae: 30.2152 - val_loss: 2418.9912 - val_mae: 33.7972\n",
      "Epoch 97/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1888.8967 - mae: 30.8034 - val_loss: 2507.4604 - val_mae: 34.3182\n",
      "Epoch 98/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1808.7615 - mae: 30.2604 - val_loss: 2395.5315 - val_mae: 33.5816\n",
      "Epoch 99/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1757.5986 - mae: 29.9481 - val_loss: 2289.5706 - val_mae: 33.0615\n",
      "Epoch 100/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1841.4650 - mae: 30.6369 - val_loss: 2780.9197 - val_mae: 36.2004\n"
     ]
    }
   ],
   "source": [
    "n_features_reg = X_train_reg_scaled.shape[1]\n",
    "\n",
    "model_reg = build_regression_model(n_features_reg)\n",
    "\n",
    "history_reg = model_reg.fit(\n",
    "    X_train_reg_scaled,\n",
    "    y_train_reg,\n",
    "    validation_data=(X_test_reg_scaled, y_test_reg),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2147148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step\n",
      "MSE: 2780.9194715110425\n",
      "RMSE: 52.73442397060048\n",
      "MAE: 36.200376147349466\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "y_pred_reg = model_reg.predict(X_test_reg_scaled).flatten()\n",
    "\n",
    "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE:\", mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2ec70a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation (RMSE / Mean Price): 0.3659523133066816\n"
     ]
    }
   ],
   "source": [
    "df[\"price\"].describe()\n",
    "\n",
    "eval = rmse/df[\"price\"].mean()\n",
    "print(\"Evaluation (RMSE / Mean Price):\", eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9067ee5",
   "metadata": {},
   "source": [
    "Hicimos research y vimos que transformar logarítmicamente el precio estabiliza la varianza y reduce la influencia de outliers, lo que nos puede servir para predecir de mejor forma. Ahora predeciremos con base en esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7424a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_reg = df[\"log_price\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e357ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_excluir_reg = [\n",
    "    \"price\",\n",
    "    \"log_price\",\n",
    "    \"estimated_revenue_l365d\"  \n",
    "]\n",
    "\n",
    "X_reg = df.drop(columns=cols_excluir_reg)\n",
    "X_reg = X_reg.select_dtypes(include=[\"number\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4b033a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a42d48d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_reg = StandardScaler()\n",
    "X_train_reg_scaled = scaler_reg.fit_transform(X_train_reg)\n",
    "X_test_reg_scaled = scaler_reg.transform(X_test_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4ce8d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_regression_model(\n",
    "    n_features,\n",
    "    n_hidden1=128,\n",
    "    n_hidden2=64,\n",
    "    n_hidden3=32,\n",
    "    dropout_rate=0.2,\n",
    "    learning_rate=1e-3\n",
    "):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(n_features,)),\n",
    "        layers.Dense(n_hidden1, activation=\"relu\"),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(n_hidden2, activation=\"relu\"),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(n_hidden3, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"linear\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00023b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.1349 - mae: 1.0096 - val_loss: 0.3382 - val_mae: 0.4499\n",
      "Epoch 2/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5530 - mae: 0.5870 - val_loss: 0.3388 - val_mae: 0.4642\n",
      "Epoch 3/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4175 - mae: 0.5107 - val_loss: 0.2212 - val_mae: 0.3628\n",
      "Epoch 4/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3389 - mae: 0.4575 - val_loss: 0.2545 - val_mae: 0.4086\n",
      "Epoch 5/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2856 - mae: 0.4203 - val_loss: 0.2428 - val_mae: 0.3990\n",
      "Epoch 6/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2546 - mae: 0.3996 - val_loss: 0.2296 - val_mae: 0.3874\n",
      "Epoch 7/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2167 - mae: 0.3646 - val_loss: 0.1892 - val_mae: 0.3467\n",
      "Epoch 8/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2009 - mae: 0.3522 - val_loss: 0.3523 - val_mae: 0.5013\n",
      "Epoch 9/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1800 - mae: 0.3314 - val_loss: 0.1877 - val_mae: 0.3494\n",
      "Epoch 10/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1701 - mae: 0.3216 - val_loss: 0.1697 - val_mae: 0.3287\n",
      "Epoch 11/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1592 - mae: 0.3103 - val_loss: 0.1602 - val_mae: 0.3165\n",
      "Epoch 12/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1543 - mae: 0.3051 - val_loss: 0.2044 - val_mae: 0.3693\n",
      "Epoch 13/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1454 - mae: 0.2964 - val_loss: 0.1771 - val_mae: 0.3387\n",
      "Epoch 14/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1451 - mae: 0.2950 - val_loss: 0.2095 - val_mae: 0.3736\n",
      "Epoch 15/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1394 - mae: 0.2893 - val_loss: 0.1594 - val_mae: 0.3178\n",
      "Epoch 16/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1354 - mae: 0.2835 - val_loss: 0.1412 - val_mae: 0.2916\n",
      "Epoch 17/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1329 - mae: 0.2811 - val_loss: 0.1583 - val_mae: 0.3163\n",
      "Epoch 18/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1302 - mae: 0.2779 - val_loss: 0.1507 - val_mae: 0.3070\n",
      "Epoch 19/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1264 - mae: 0.2740 - val_loss: 0.1344 - val_mae: 0.2819\n",
      "Epoch 20/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1243 - mae: 0.2720 - val_loss: 0.1252 - val_mae: 0.2685\n",
      "Epoch 21/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1223 - mae: 0.2692 - val_loss: 0.1218 - val_mae: 0.2627\n",
      "Epoch 22/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1188 - mae: 0.2647 - val_loss: 0.1361 - val_mae: 0.2867\n",
      "Epoch 23/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1161 - mae: 0.2611 - val_loss: 0.1210 - val_mae: 0.2623\n",
      "Epoch 24/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1167 - mae: 0.2632 - val_loss: 0.1219 - val_mae: 0.2668\n",
      "Epoch 25/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1135 - mae: 0.2574 - val_loss: 0.1198 - val_mae: 0.2609\n",
      "Epoch 26/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1122 - mae: 0.2576 - val_loss: 0.1199 - val_mae: 0.2617\n",
      "Epoch 27/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1098 - mae: 0.2544 - val_loss: 0.1252 - val_mae: 0.2727\n",
      "Epoch 28/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1087 - mae: 0.2528 - val_loss: 0.1229 - val_mae: 0.2677\n",
      "Epoch 29/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1059 - mae: 0.2490 - val_loss: 0.1172 - val_mae: 0.2600\n",
      "Epoch 30/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1046 - mae: 0.2459 - val_loss: 0.1238 - val_mae: 0.2709\n",
      "Epoch 31/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1024 - mae: 0.2447 - val_loss: 0.1167 - val_mae: 0.2558\n",
      "Epoch 32/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1024 - mae: 0.2439 - val_loss: 0.1143 - val_mae: 0.2504\n",
      "Epoch 33/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1002 - mae: 0.2417 - val_loss: 0.1146 - val_mae: 0.2521\n",
      "Epoch 34/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0987 - mae: 0.2392 - val_loss: 0.1153 - val_mae: 0.2552\n",
      "Epoch 35/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0973 - mae: 0.2386 - val_loss: 0.1173 - val_mae: 0.2546\n",
      "Epoch 36/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0962 - mae: 0.2369 - val_loss: 0.1171 - val_mae: 0.2575\n",
      "Epoch 37/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0928 - mae: 0.2325 - val_loss: 0.1124 - val_mae: 0.2480\n",
      "Epoch 38/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0933 - mae: 0.2331 - val_loss: 0.1183 - val_mae: 0.2571\n",
      "Epoch 39/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0929 - mae: 0.2319 - val_loss: 0.1173 - val_mae: 0.2549\n",
      "Epoch 40/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0917 - mae: 0.2303 - val_loss: 0.1169 - val_mae: 0.2526\n",
      "Epoch 41/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0928 - mae: 0.2327 - val_loss: 0.1109 - val_mae: 0.2466\n",
      "Epoch 42/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0902 - mae: 0.2294 - val_loss: 0.1169 - val_mae: 0.2573\n",
      "Epoch 43/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0898 - mae: 0.2286 - val_loss: 0.1145 - val_mae: 0.2531\n",
      "Epoch 44/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0882 - mae: 0.2260 - val_loss: 0.1171 - val_mae: 0.2591\n",
      "Epoch 45/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0874 - mae: 0.2253 - val_loss: 0.1166 - val_mae: 0.2542\n",
      "Epoch 46/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0868 - mae: 0.2240 - val_loss: 0.1177 - val_mae: 0.2584\n",
      "Epoch 47/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0848 - mae: 0.2228 - val_loss: 0.1118 - val_mae: 0.2472\n",
      "Epoch 48/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0849 - mae: 0.2230 - val_loss: 0.1086 - val_mae: 0.2431\n",
      "Epoch 49/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0862 - mae: 0.2228 - val_loss: 0.1075 - val_mae: 0.2425\n",
      "Epoch 50/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0833 - mae: 0.2204 - val_loss: 0.1121 - val_mae: 0.2489\n",
      "Epoch 51/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0846 - mae: 0.2213 - val_loss: 0.1123 - val_mae: 0.2482\n",
      "Epoch 52/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0830 - mae: 0.2190 - val_loss: 0.1101 - val_mae: 0.2475\n",
      "Epoch 53/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0824 - mae: 0.2196 - val_loss: 0.1096 - val_mae: 0.2444\n",
      "Epoch 54/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0806 - mae: 0.2165 - val_loss: 0.1125 - val_mae: 0.2472\n",
      "Epoch 55/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0814 - mae: 0.2175 - val_loss: 0.1139 - val_mae: 0.2499\n",
      "Epoch 56/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0802 - mae: 0.2164 - val_loss: 0.1137 - val_mae: 0.2492\n",
      "Epoch 57/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0797 - mae: 0.2160 - val_loss: 0.1195 - val_mae: 0.2590\n",
      "Epoch 58/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0774 - mae: 0.2126 - val_loss: 0.1103 - val_mae: 0.2428\n",
      "Epoch 59/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0802 - mae: 0.2159 - val_loss: 0.1092 - val_mae: 0.2439\n",
      "Epoch 60/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0797 - mae: 0.2147 - val_loss: 0.1076 - val_mae: 0.2399\n",
      "Epoch 61/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0770 - mae: 0.2121 - val_loss: 0.1200 - val_mae: 0.2643\n",
      "Epoch 62/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0774 - mae: 0.2111 - val_loss: 0.1074 - val_mae: 0.2427\n",
      "Epoch 63/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0756 - mae: 0.2105 - val_loss: 0.1106 - val_mae: 0.2453\n",
      "Epoch 64/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0764 - mae: 0.2100 - val_loss: 0.1073 - val_mae: 0.2415\n",
      "Epoch 65/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0760 - mae: 0.2097 - val_loss: 0.1119 - val_mae: 0.2464\n",
      "Epoch 66/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0739 - mae: 0.2077 - val_loss: 0.1126 - val_mae: 0.2494\n",
      "Epoch 67/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0756 - mae: 0.2092 - val_loss: 0.1100 - val_mae: 0.2426\n",
      "Epoch 68/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0749 - mae: 0.2102 - val_loss: 0.1091 - val_mae: 0.2426\n",
      "Epoch 69/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0746 - mae: 0.2078 - val_loss: 0.1143 - val_mae: 0.2509\n",
      "Epoch 70/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0731 - mae: 0.2070 - val_loss: 0.1067 - val_mae: 0.2404\n",
      "Epoch 71/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0753 - mae: 0.2080 - val_loss: 0.1130 - val_mae: 0.2469\n",
      "Epoch 72/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0715 - mae: 0.2041 - val_loss: 0.1075 - val_mae: 0.2402\n",
      "Epoch 73/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0744 - mae: 0.2080 - val_loss: 0.1092 - val_mae: 0.2442\n",
      "Epoch 74/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0729 - mae: 0.2050 - val_loss: 0.1146 - val_mae: 0.2528\n",
      "Epoch 75/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0713 - mae: 0.2044 - val_loss: 0.1105 - val_mae: 0.2423\n",
      "Epoch 76/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0706 - mae: 0.2031 - val_loss: 0.1148 - val_mae: 0.2536\n",
      "Epoch 77/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0726 - mae: 0.2051 - val_loss: 0.1096 - val_mae: 0.2434\n",
      "Epoch 78/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0725 - mae: 0.2055 - val_loss: 0.1072 - val_mae: 0.2403\n",
      "Epoch 79/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0700 - mae: 0.2019 - val_loss: 0.1107 - val_mae: 0.2459\n",
      "Epoch 80/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0709 - mae: 0.2023 - val_loss: 0.1100 - val_mae: 0.2396\n",
      "Epoch 81/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0718 - mae: 0.2042 - val_loss: 0.1132 - val_mae: 0.2466\n",
      "Epoch 82/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0707 - mae: 0.2024 - val_loss: 0.1071 - val_mae: 0.2395\n",
      "Epoch 83/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0700 - mae: 0.2017 - val_loss: 0.1102 - val_mae: 0.2415\n",
      "Epoch 84/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0695 - mae: 0.2009 - val_loss: 0.1092 - val_mae: 0.2426\n",
      "Epoch 85/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0691 - mae: 0.2002 - val_loss: 0.1113 - val_mae: 0.2436\n",
      "Epoch 86/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0685 - mae: 0.2003 - val_loss: 0.1076 - val_mae: 0.2396\n",
      "Epoch 87/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0704 - mae: 0.2022 - val_loss: 0.1045 - val_mae: 0.2372\n",
      "Epoch 88/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0686 - mae: 0.1999 - val_loss: 0.1087 - val_mae: 0.2407\n",
      "Epoch 89/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0680 - mae: 0.1989 - val_loss: 0.1133 - val_mae: 0.2473\n",
      "Epoch 90/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0692 - mae: 0.2006 - val_loss: 0.1084 - val_mae: 0.2411\n",
      "Epoch 91/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0675 - mae: 0.1981 - val_loss: 0.1066 - val_mae: 0.2393\n",
      "Epoch 92/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0681 - mae: 0.2004 - val_loss: 0.1117 - val_mae: 0.2477\n",
      "Epoch 93/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0678 - mae: 0.1988 - val_loss: 0.1094 - val_mae: 0.2424\n",
      "Epoch 94/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0673 - mae: 0.1988 - val_loss: 0.1087 - val_mae: 0.2410\n",
      "Epoch 95/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0670 - mae: 0.1965 - val_loss: 0.1095 - val_mae: 0.2410\n",
      "Epoch 96/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0656 - mae: 0.1966 - val_loss: 0.1082 - val_mae: 0.2383\n",
      "Epoch 97/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0675 - mae: 0.1974 - val_loss: 0.1055 - val_mae: 0.2359\n",
      "Epoch 98/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0667 - mae: 0.1960 - val_loss: 0.1064 - val_mae: 0.2395\n",
      "Epoch 99/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0656 - mae: 0.1958 - val_loss: 0.1059 - val_mae: 0.2383\n",
      "Epoch 100/100\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0662 - mae: 0.1962 - val_loss: 0.1064 - val_mae: 0.2377\n"
     ]
    }
   ],
   "source": [
    "n_features_reg = X_train_reg_scaled.shape[1]\n",
    "\n",
    "model_reg_log = build_regression_model(n_features_reg)\n",
    "\n",
    "history_reg_log = model_reg_log.fit(\n",
    "    X_train_reg_scaled,\n",
    "    y_train_reg,\n",
    "    validation_data=(X_test_reg_scaled, y_test_reg),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3120bb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    }
   ],
   "source": [
    "y_pred_log = model_reg_log.predict(X_test_reg_scaled).flatten()\n",
    "\n",
    "# Convertir log_price → price\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_true = np.expm1(y_test_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e7ca248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2323.4104729739647\n",
      "RMSE: 48.20176835940736\n",
      "MAE: 31.88671233837968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36dafc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 22:08:17 INFO mlflow.tracking.fluent: Experiment with name 'airbnb-barcelona-reg-nn' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment ID (reg): 614581612292287758\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\") \n",
    "experiment_reg = mlflow.set_experiment(\"airbnb-barcelona-reg-nn\")\n",
    "print(\"Experiment ID (reg):\", experiment_reg.experiment_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76fedeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_regression_model(\n",
    "    n_features,\n",
    "    n_hidden1=128,\n",
    "    n_hidden2=64,\n",
    "    n_hidden3=32,\n",
    "    dropout_rate=0.2,\n",
    "    learning_rate=1e-3\n",
    "):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(n_features,)),\n",
    "        layers.Dense(n_hidden1, activation=\"relu\"),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(n_hidden2, activation=\"relu\"),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(n_hidden3, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"linear\")  # regresión\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22f32267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def run_mlflow_reg(\n",
    "    n_hidden1=128,\n",
    "    n_hidden2=64,\n",
    "    n_hidden3=32,\n",
    "    dropout_rate=0.2,\n",
    "    learning_rate=1e-3,\n",
    "    epochs=80,\n",
    "    batch_size=32,\n",
    "    run_name=\"reg_base\",\n",
    "    experiment_id=None\n",
    "):\n",
    "    n_features_reg = X_train_reg_scaled.shape[1]\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name, experiment_id=experiment_id):\n",
    "\n",
    "        # Log hiperparámetros\n",
    "        mlflow.log_param(\"n_hidden1\", n_hidden1)\n",
    "        mlflow.log_param(\"n_hidden2\", n_hidden2)\n",
    "        mlflow.log_param(\"n_hidden3\", n_hidden3)\n",
    "        mlflow.log_param(\"dropout_rate\", dropout_rate)\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "\n",
    "        # Construir modelo\n",
    "        model = build_regression_model(\n",
    "            n_features=n_features_reg,\n",
    "            n_hidden1=n_hidden1,\n",
    "            n_hidden2=n_hidden2,\n",
    "            n_hidden3=n_hidden3,\n",
    "            dropout_rate=dropout_rate,\n",
    "            learning_rate=learning_rate\n",
    "        )\n",
    "\n",
    "        # Entrenar\n",
    "        history = model.fit(\n",
    "            X_train_reg_scaled,\n",
    "            y_train_reg,\n",
    "            validation_data=(X_test_reg_scaled, y_test_reg),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Predicción en escala log\n",
    "        y_pred_log = model.predict(X_test_reg_scaled).flatten()\n",
    "\n",
    "        # Volver a precio real (euros)\n",
    "        y_true = np.expm1(y_test_reg)\n",
    "        y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "        # Métricas reales\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        mean_price = y_true.mean()\n",
    "        rel_rmse = rmse / mean_price\n",
    "\n",
    "        # Log métricas\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"rmse_over_mean_price\", rel_rmse)\n",
    "\n",
    "        # Guardar modelo\n",
    "        mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "        print(f\"Run '{run_name}' -> RMSE={rmse:.2f}, MAE={mae:.2f}, RMSE/Mean={rel_rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d42e5e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_reg = [\n",
    "    # ---- MODELOS PEQUEÑOS ----\n",
    "    {\"run_name\": \"reg_small_1\", \"n_hidden1\": 32,  \"n_hidden2\": 16,  \"n_hidden3\": 8,   \"learning_rate\": 1e-3, \"dropout_rate\": 0.1, \"epochs\": 60,  \"batch_size\": 32},\n",
    "    {\"run_name\": \"reg_small_2\", \"n_hidden1\": 32,  \"n_hidden2\": 16,  \"n_hidden3\": 8,   \"learning_rate\": 5e-4, \"dropout_rate\": 0.1, \"epochs\": 80,  \"batch_size\": 32},\n",
    "    {\"run_name\": \"reg_small_3\", \"n_hidden1\": 64,  \"n_hidden2\": 32,  \"n_hidden3\": 16,  \"learning_rate\": 1e-3, \"dropout_rate\": 0.2, \"epochs\": 50,  \"batch_size\": 64},\n",
    "    {\"run_name\": \"reg_small_4\", \"n_hidden1\": 16,  \"n_hidden2\": 8,   \"n_hidden3\": 4,   \"learning_rate\": 1e-3, \"dropout_rate\": 0.0, \"epochs\": 50,  \"batch_size\": 32},\n",
    "    {\"run_name\": \"reg_small_5\", \"n_hidden1\": 16,  \"n_hidden2\": 8,   \"n_hidden3\": 4,   \"learning_rate\": 5e-4, \"dropout_rate\": 0.1, \"epochs\": 70,  \"batch_size\": 32},\n",
    "\n",
    "    # ---- MODELOS MEDIOS ----\n",
    "    {\"run_name\": \"reg_medium_1\", \"n_hidden1\": 128, \"n_hidden2\": 64,  \"n_hidden3\": 32, \"learning_rate\": 1e-3, \"dropout_rate\": 0.2, \"epochs\": 80,  \"batch_size\": 32},\n",
    "    {\"run_name\": \"reg_medium_2\", \"n_hidden1\": 128, \"n_hidden2\": 64,  \"n_hidden3\": 32, \"learning_rate\": 5e-4, \"dropout_rate\": 0.3, \"epochs\": 90,  \"batch_size\": 32},\n",
    "    {\"run_name\": \"reg_medium_3\", \"n_hidden1\": 256, \"n_hidden2\": 128, \"n_hidden3\": 64, \"learning_rate\": 1e-3, \"dropout_rate\": 0.2, \"epochs\": 70,  \"batch_size\": 64},\n",
    "    {\"run_name\": \"reg_medium_4\", \"n_hidden1\": 64,  \"n_hidden2\": 64,  \"n_hidden3\": 32, \"learning_rate\": 3e-4, \"dropout_rate\": 0.2, \"epochs\": 90,  \"batch_size\": 32},\n",
    "    {\"run_name\": \"reg_medium_5\", \"n_hidden1\": 128, \"n_hidden2\": 64,  \"n_hidden3\": 32, \"learning_rate\": 1e-4, \"dropout_rate\": 0.2, \"epochs\": 100, \"batch_size\": 32},\n",
    "\n",
    "    # ---- MODELOS GRANDES ----\n",
    "    {\"run_name\": \"reg_large_1\", \"n_hidden1\": 256, \"n_hidden2\": 128, \"n_hidden3\": 64,  \"learning_rate\": 1e-3, \"dropout_rate\": 0.3, \"epochs\": 100, \"batch_size\": 32},\n",
    "    {\"run_name\": \"reg_large_2\", \"n_hidden1\": 256, \"n_hidden2\": 128, \"n_hidden3\": 64,  \"learning_rate\": 5e-4, \"dropout_rate\": 0.3, \"epochs\": 120, \"batch_size\": 32},\n",
    "    {\"run_name\": \"reg_large_3\", \"n_hidden1\": 512, \"n_hidden2\": 256, \"n_hidden3\": 128, \"learning_rate\": 3e-4, \"dropout_rate\": 0.3, \"epochs\": 120, \"batch_size\": 64},\n",
    "    {\"run_name\": \"reg_large_4\", \"n_hidden1\": 512, \"n_hidden2\": 256, \"n_hidden3\": 128, \"learning_rate\": 1e-4, \"dropout_rate\": 0.4, \"epochs\": 140, \"batch_size\": 32},\n",
    "    {\"run_name\": \"reg_large_5\", \"n_hidden1\": 256, \"n_hidden2\": 128, \"n_hidden3\": 64,  \"learning_rate\": 2e-4, \"dropout_rate\": 0.3, \"epochs\": 140, \"batch_size\": 32},\n",
    "\n",
    "    # ---- VARIANDO LEARNING RATE ----\n",
    "    {\"run_name\": \"reg_lr_1e_minus2\", \"n_hidden1\": 64,  \"n_hidden2\": 32,  \"n_hidden3\": 16, \"learning_rate\": 1e-2, \"dropout_rate\": 0.2, \"epochs\": 40,  \"batch_size\": 32},\n",
    "    {\"run_name\": \"reg_lr_5e_minus3\", \"n_hidden1\": 64,  \"n_hidden2\": 32,  \"n_hidden3\": 16, \"learning_rate\": 5e-3, \"dropout_rate\": 0.2, \"epochs\": 50,  \"batch_size\": 32},\n",
    "    {\"run_name\": \"reg_lr_3e_minus4\", \"n_hidden1\": 128, \"n_hidden2\": 64,  \"n_hidden3\": 32, \"learning_rate\": 3e-4, \"dropout_rate\": 0.2, \"epochs\": 100, \"batch_size\": 32},\n",
    "    {\"run_name\": \"reg_lr_1e_minus4\", \"n_hidden1\": 128, \"n_hidden2\": 64,  \"n_hidden3\": 32, \"learning_rate\": 1e-4, \"dropout_rate\": 0.3, \"epochs\": 120, \"batch_size\": 32},\n",
    "    {\"run_name\": \"reg_lr_5e_minus5\", \"n_hidden1\": 256, \"n_hidden2\": 128, \"n_hidden3\": 64, \"learning_rate\": 5e-5, \"dropout_rate\": 0.2, \"epochs\": 150, \"batch_size\": 32},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0d942c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Corriendo reg_small_1 ===\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 22:09:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 22:09:14 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/11/30 22:09:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'reg_small_1' -> RMSE=54.35, MAE=36.72, RMSE/Mean=0.378\n",
      "🏃 View run reg_small_1 at: http://localhost:5000/#/experiments/614581612292287758/runs/bf7d5f3da9ef49058ff116a4da179496\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/614581612292287758\n",
      "\n",
      "=== Corriendo reg_small_2 ===\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 22:10:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 22:10:01 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/11/30 22:10:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'reg_small_2' -> RMSE=58.34, MAE=39.28, RMSE/Mean=0.406\n",
      "🏃 View run reg_small_2 at: http://localhost:5000/#/experiments/614581612292287758/runs/64a3b47880ea471689e10608028d8463\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/614581612292287758\n",
      "\n",
      "=== Corriendo reg_small_3 ===\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 22:10:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 22:10:27 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/11/30 22:10:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'reg_small_3' -> RMSE=74.21, MAE=51.26, RMSE/Mean=0.516\n",
      "🏃 View run reg_small_3 at: http://localhost:5000/#/experiments/614581612292287758/runs/b3ef5c4b57f44ed39a07c22afd286a19\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/614581612292287758\n",
      "\n",
      "=== Corriendo reg_small_4 ===\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 22:10:59 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 22:11:00 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/11/30 22:11:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'reg_small_4' -> RMSE=55.79, MAE=38.81, RMSE/Mean=0.388\n",
      "🏃 View run reg_small_4 at: http://localhost:5000/#/experiments/614581612292287758/runs/708814e2c8a748158ec21ec04d4900b1\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/614581612292287758\n",
      "\n",
      "=== Corriendo reg_small_5 ===\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 22:11:42 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 22:11:42 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/11/30 22:11:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'reg_small_5' -> RMSE=63.78, MAE=43.77, RMSE/Mean=0.443\n",
      "🏃 View run reg_small_5 at: http://localhost:5000/#/experiments/614581612292287758/runs/de96cae6326f4618931394a324fb588f\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/614581612292287758\n",
      "\n",
      "=== Corriendo reg_medium_1 ===\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 22:12:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 22:12:29 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/11/30 22:12:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'reg_medium_1' -> RMSE=51.12, MAE=33.42, RMSE/Mean=0.355\n",
      "🏃 View run reg_medium_1 at: http://localhost:5000/#/experiments/614581612292287758/runs/f175df81af224d33b2695040ad177887\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/614581612292287758\n",
      "\n",
      "=== Corriendo reg_medium_2 ===\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 22:13:22 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 22:13:22 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/11/30 22:13:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'reg_medium_2' -> RMSE=51.67, MAE=34.18, RMSE/Mean=0.359\n",
      "🏃 View run reg_medium_2 at: http://localhost:5000/#/experiments/614581612292287758/runs/ec5b2eb6fd8b49d5bdda11ba2d10fa97\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/614581612292287758\n",
      "\n",
      "=== Corriendo reg_medium_3 ===\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 22:13:56 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 22:13:56 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/11/30 22:14:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'reg_medium_3' -> RMSE=53.06, MAE=34.35, RMSE/Mean=0.369\n",
      "🏃 View run reg_medium_3 at: http://localhost:5000/#/experiments/614581612292287758/runs/0e2f439400de4104afe4702bf2d68656\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/614581612292287758\n",
      "\n",
      "=== Corriendo reg_medium_4 ===\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 22:14:49 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 22:14:50 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/11/30 22:14:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'reg_medium_4' -> RMSE=53.80, MAE=35.92, RMSE/Mean=0.374\n",
      "🏃 View run reg_medium_4 at: http://localhost:5000/#/experiments/614581612292287758/runs/514ec4334d0c41ed85fb99765dc44474\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/614581612292287758\n",
      "\n",
      "=== Corriendo reg_medium_5 ===\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 22:15:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 22:15:47 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/11/30 22:15:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'reg_medium_5' -> RMSE=55.74, MAE=37.34, RMSE/Mean=0.388\n",
      "🏃 View run reg_medium_5 at: http://localhost:5000/#/experiments/614581612292287758/runs/f4e31deec1f44e6b8f8f0bd5e0f20571\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/614581612292287758\n",
      "\n",
      "=== Corriendo reg_large_1 ===\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 22:16:47 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 22:16:47 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/11/30 22:16:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'reg_large_1' -> RMSE=47.64, MAE=31.13, RMSE/Mean=0.331\n",
      "🏃 View run reg_large_1 at: http://localhost:5000/#/experiments/614581612292287758/runs/177e273cf56d4db09ec5771f15c72bee\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/614581612292287758\n",
      "\n",
      "=== Corriendo reg_large_2 ===\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 22:17:58 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 22:17:58 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/11/30 22:18:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'reg_large_2' -> RMSE=50.61, MAE=32.93, RMSE/Mean=0.352\n",
      "🏃 View run reg_large_2 at: http://localhost:5000/#/experiments/614581612292287758/runs/e3d0c53c349443358d96d68a8008ee99\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/614581612292287758\n",
      "\n",
      "=== Corriendo reg_large_3 ===\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 22:19:07 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 22:19:07 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/11/30 22:19:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'reg_large_3' -> RMSE=51.23, MAE=33.21, RMSE/Mean=0.356\n",
      "🏃 View run reg_large_3 at: http://localhost:5000/#/experiments/614581612292287758/runs/fe11b4820dfd400aa1974f1fa9f5296e\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/614581612292287758\n",
      "\n",
      "=== Corriendo reg_large_4 ===\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 22:21:16 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 22:21:16 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/11/30 22:21:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'reg_large_4' -> RMSE=53.52, MAE=34.81, RMSE/Mean=0.372\n",
      "🏃 View run reg_large_4 at: http://localhost:5000/#/experiments/614581612292287758/runs/455b40983099498a942f3bf3419322bd\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/614581612292287758\n",
      "\n",
      "=== Corriendo reg_large_5 ===\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 22:25:03 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 22:25:04 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/11/30 22:25:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'reg_large_5' -> RMSE=51.55, MAE=33.46, RMSE/Mean=0.358\n",
      "🏃 View run reg_large_5 at: http://localhost:5000/#/experiments/614581612292287758/runs/9de814b7792740a0bb4d38cddd3b78af\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/614581612292287758\n",
      "\n",
      "=== Corriendo reg_lr_1e_minus2 ===\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 22:25:34 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 22:25:34 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/11/30 22:25:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'reg_lr_1e_minus2' -> RMSE=65.52, MAE=44.58, RMSE/Mean=0.456\n",
      "🏃 View run reg_lr_1e_minus2 at: http://localhost:5000/#/experiments/614581612292287758/runs/bc2e8614d0024d83b2075851a543bd14\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/614581612292287758\n",
      "\n",
      "=== Corriendo reg_lr_5e_minus3 ===\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 22:26:08 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 22:26:09 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/11/30 22:26:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'reg_lr_5e_minus3' -> RMSE=57.80, MAE=38.73, RMSE/Mean=0.402\n",
      "🏃 View run reg_lr_5e_minus3 at: http://localhost:5000/#/experiments/614581612292287758/runs/e4e3cc6cf018480ba28aa05522772054\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/614581612292287758\n",
      "\n",
      "=== Corriendo reg_lr_3e_minus4 ===\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 22:27:05 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 22:27:06 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/11/30 22:27:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'reg_lr_3e_minus4' -> RMSE=53.12, MAE=35.13, RMSE/Mean=0.369\n",
      "🏃 View run reg_lr_3e_minus4 at: http://localhost:5000/#/experiments/614581612292287758/runs/7a4f4aa92bdd43b0a7e73d6bbd34dfdf\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/614581612292287758\n",
      "\n",
      "=== Corriendo reg_lr_1e_minus4 ===\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 22:28:12 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 22:28:13 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/11/30 22:28:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'reg_lr_1e_minus4' -> RMSE=59.55, MAE=39.95, RMSE/Mean=0.414\n",
      "🏃 View run reg_lr_1e_minus4 at: http://localhost:5000/#/experiments/614581612292287758/runs/2bbd7a21825a4cf3a05f0436dcdb1935\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/614581612292287758\n",
      "\n",
      "=== Corriendo reg_lr_5e_minus5 ===\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 22:30:20 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 22:30:20 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/11/30 22:30:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'reg_lr_5e_minus5' -> RMSE=54.69, MAE=36.40, RMSE/Mean=0.380\n",
      "🏃 View run reg_lr_5e_minus5 at: http://localhost:5000/#/experiments/614581612292287758/runs/fd944968e3ca410a900df6d20d4cbbb5\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/614581612292287758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cfg in configs_reg:\n",
    "    print(f\"=== Corriendo {cfg['run_name']} ===\")\n",
    "    run_mlflow_reg(**cfg, experiment_id=experiment_reg.experiment_id)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
